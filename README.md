# MADE_project_2023
Репозиторий для группового проекта построения модели генерации фейкдокументов.

## Описание проекта 
Фейковые, сгенерированные нейросетями документы все чаще встречаются на просторах сети, прогнозируется их активный рост. В связи с этим, поисковые системы должны иметь устойчивость к подобного рода текстам, картинкам, видео и другим файлам, чтобы уберечь пользователей от искусственно созданной информации. Устойчивость можно проверить на практике, создав модель, генерирующую фейковые документы. Область изучения здесь открыта, хотя есть несколько удачных статей.
Задача проекта - создать модель генерации основанную на Transformer подобных архитектурах, которая может быть завернута в Python библиотеку с возможностью запуска основного функционала (в том числе генерации текстов) из командной строки. При желании можно оформить в виде сервиса с веб-интерфейсом, который принимает запрос и генерирует простую html страницу с текстом документа. Важным критерием будет то, насколько успешно сгенерированные документы смогут обмануть систему: насколько они хорошо ранжируются, являются правдоподобными.

## Параметры генерации фейкового документа
Использовалась модель `sberbank-ai/rugpt3medium_based_on_gpt2`

В ноутбуке рассмотреные некоторые параметры генерации текста с подсчетом метрик на части датасета `MS MARCO`.

Для подстеча метрик была использована библиотека [ranking_metrics](https://pypi.org/project/docs-ranking-metrics/)


[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/10VueXxB-o6Nj5ccgcDidmIGvV4HtffZV)

  
## Полезные ссылки

1. [Transformers Doc](https://huggingface.co/docs/transformers/performance)
2. [Введение в Transformers и Hugging Face](https://habr.com/ru/articles/704592/)
3. [Оценка выпускного проекта](https://data.vk.company/blog/topic/view/21655/)
4. [Тюнинг GPT-like моделей](https://habr.com/ru/companies/neoflex/articles/722584/)

